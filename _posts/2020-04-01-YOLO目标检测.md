---
layout: post
title: YOLO-V1目标检测
date: 2020-02-08 23:18 +0800
last_modified_at: 2020-02-09 02:08:25 +0800
tags: [CV、目标检测、YOLO]
toc:  true
---
{: .message }


### YOLO目标检测

#### 摘要

YOLO把检测问题当做一个regression problem，空间上将边框预测和类别预测分离了，整个预测在整个图像上一次evaluation。YOLO标准本可以达到**45fps，FastYOLO可以达到155fps**，mAP还是可以达到当前最好的检测器的mAP。相比其他的检测器：YOLO定位误差更大，将背景错误预测成目标的概率降低了；YOLO学习到了目标更普遍性的特征，比如将算法迁移到其他场景如艺术品识别中效果还是很好。

####一、背景

与基于two-stage的目标检测算法相比，YOLO系列的目标检测算法使用的直接回归的思想进行检测，没有RPN之类的需要预测bbox的步骤，可以直接回归。算法优势速度快，同时检测的精度还是可以的。整体上把目标检测任务看作是目标区域预测和类别预测的回归问题，采用单个神经网络直接预测目标的边界和类别，实现了端到端的检测。YOLO结构如下：

![1526956557757](Temp\1526956557757.png)

**YOLO的优势**：

- YOLO特别快，基本版本45fps，Fast版本155fps。
- YOLO在预测时候是基于全局信息的。在测试和训练中see the entire image，因此，encode了目标的类别以及是否出现的上下文信息。这里其他的two-stage的算法，因为只在roi上做预测，没有上下文信息，容易将背景预测成目标，假阳率增加。YOLO在这块错误率降低了一半左右。
- YOLO学习到了目标的更一般的特性。当在自然图像上训练，可以在艺术品图上识别；另外，当有unexpected  input时候，YOLO不容易break down。

**YOLO不足和限制**：

- 定位精度差，因为其在一次性预测中定位精度和类别。比较难，特别是在小目标上精度更低；另一方面，因为虽然加了根号，但是定位误差，大小box的误差相同对待的，但是不同相等对待，同样的误差，大box的影响要比小box对IOU影响要小。
- 预测的box个数是固定的，同一个cell只预测了2个box，对于那种有多个目连在一起的情况就没法准确预测了。目标的个数有上限。比如一群鸟预测，就出了问题。
- yolo的box的预测是从数据中预测的，因此，对于新的或者是不常见角度或者是不常见长宽比的的目标是无法准确识别以及预测其box的。（自己理解：因为YOLO的边框是来自于数据，没有Anchor以及SSD的预先设定的框，这样导致eg数据集中大部分GT都是正方形的，这样训练出的YOLO对于比如极端点的长方形就很难预测了）
- 该算法核心的error就是定位的误差。

 

**2、之前的two-stage的方法的不足**：

- 算法流程复杂，需要先预测出bbox，再识别与回归。比较难优化。
- 训练困难，存在RPN和CNN的双重训练。
- 速度慢，流程较多，识别的时候速度慢。



#### 二、Unified Detection

#####1、算法框架和思路

（1）YOLO将整个图像分为S*S个格子（grid cell）。在训练的时候，如果一个目标的中心落入某个grid cell，这个cell就负责检测该目标。（这里是以cell来做判别和match GT）

（2）每个cell预测B个box（实际：B=2），每个box预测一个置信值Confidence和四个位置的偏移量x、y、w、h，x和y代表了box的中心相对与cell边界的偏移，w和h是相对整个图像的高度和宽度。在预测中，Confidence代表了预测的Box与GT之间的IOU。

每个cell预测C个类别（eg：VOC就是20个类别）。这样一个cell就预测了（B* 5 + C）个值，整个图像上预测了：

![1526958570626](Temp\1526958570626.png)

个值的tensor张量。

![1526959795473](Temp\1526959795473.png)

（3）**关于置信度**：置信值Confidence代表了该box含有一个目标的置信度以及认为当前预测正确的精确度。正式定义为Confidence为：![1526959559732](Temp\1526959559732.png)

注意这里的Confidence的正式定义，Pr（Objecet）是一个cell是否含有一个目标的概率，在训练的时候，就是0或者1，因此，在实际训练中，如果一个cell负责了一个目标，那么这个cell中两个box的置信度的label分别为两个box与GT之间的IOU；如果一个cell没有负责一个目标，那么这个cell中两个box的置信度的label为0。

**注意点：**

- 每个cell预测C个类别的条件概率![1526959131291](Temp\1526959131291.png)这个条件概率的前提是一个cell含有了一个目标。在测试的时候，将预测的条件类别概率乘以Confidence：

  ![1526959284764](Temp\1526959284764.png)

  

  这样就得到最后预测的每个box的每个特定类别的置信度的socre。这个score encode了特定类别出现在box中的概率以及这个预测的box正确的可能性。

- 类别概率是每个cell格子预测每个类别的概率值，概率的预测是对应于一个cell的 ，不是针对每个box预测概率值。但是Confidence和坐标长宽等5个值是针对特定的box的。

#####2、算法训练

![1536029366324](Temp\1536029366324.png)

**总的损失函数如下**

![1536029429182](Temp\1536029429182.png)

loss公式中： 1i(obj)表示目标中心在第i个cell中，1ij(obj)表示第i个cell中第j个box负责了这个预测。对于loss的惩罚，如果一个目标在一个cell中，会对这个cell的分类loss加惩罚；如果一个box预测器对一个预测负责（目标落在一个cell中，且cell中多个box与GT的IOU最大的那个box），会惩罚其位置损失。

**需要注意以下几点**：

- 置信值的误差：计算了所有的box的置信度误差，无论是否含有目标的box的置信度都参加了误差的计算。因为不含目标的box很多，所有其在总的误差中的比例小，乘以一个小于1的系数为0.5；对于有目标的cell的box的Confidence，其误差乘以系数5。
- -坐标预测的误差：整个框要确定需要知道其坐标x和y，以及宽度w和高度h，计算坐标误差的时候只计算了含有目标对应的box的误差。由于含有目标的box的数目少，因此，这部分误差前面加了一个大于1的系数，取值为5.
- 类别预测的误差：类别是整个cell格子预测一个类别，对应误差是整个概率向量进行作差计算误差，这里也是只计算了有目标的cell的分类概率的误差。
- 计算边框误差是长宽的开方：因为大的box如果预测的值和真实的ground truth差一点点，与小的box如果预测的值和真实的ground truth差一点，小box的偏差实际是更大的。Eg：长宽各偏移10个像素，但是对于大box来说这个误差很小，对于长宽都是10的小box来说，这点小偏差就很大了，不能忍。

**为什么要加5 和0.5的loss的权重**：

如果不对包含和不包含目标的cell和box的loss同等对待，一方面这不是很ideal，另一方面，一个大图像中，可能没有目标或者是目标很少，这导致了大部分的cell的box的confidence 必须push到0，这样不含有目标的cell和box的梯度将占据主导，超过有目标的cell和box的误差对应的梯度。这将导致模型的不稳定，以及训练的时候提前终止和收敛。

**为什么长宽loss要开根号**：

不加根号，这样大box和小box的error是同等重要的。但是这是不符合逻辑的，比如小的偏移，在大box中的影响比在小box中的影响要小很多。所以开根号，降低这个误差。

**为什么整体loss用平方误差损失**：

在这里使用平方误差loss，即sum-squard loss，是因为这个平方误差和的loss更好去优化optimize。



##### 3、网络结构

![1526960227974](Temp\1526960227974.png)

在训练时候注意点：

- 开始是一个224 * 224输入的图像分类模型。在ImageNet上训练分类模型。

- 再将分类模型上加卷积层和fc层，变成检测模型，输入为448 * 448.

- 最后一层后加了一个线性激活层，其余的层加的都是leak-relu层：

  ![1526961176544](Temp\1526961176544.png)

##### 4、其他

1、在训练的过程中，在每个grid cell会预测多个Box，在训练的时候，只希望一个box来负责预测一个GT，每个GT只有一个box来预测，选择IOU最大的box（这里自己理解是：先根据GT中心点将GT对应到cell，再在cell中2box选择IOU最大的来作为一个Box与GT对应，这样最后其实每个GT只有一个Box与之对应）。这样好处是：每个位置cell的Box预测都是不同的、特殊的，更擅长去预测特定size、长宽比、特定类别的目标，这会提高recall。这里有点SSD的味道了。

2、在网络前向预测的时候，一些大的目标（因为大的目标中心一般处在map的最中心，会在四个cell的中心）或者是目标处在多个cell的边缘上，将会被多个cell预测到，后面再经过NMS处理，这会对mAP提升了2% ~3%。



#### 三、其他细节理解

7、关于YOLO算法为何具有全局的信息，基于全图来进行预测的一些思考

因为最后预测出7*7*30个值之前是FC层后的结果，因此这里最后的7*7*30个神经元与之前的所有的卷积后的结果都相连了，所以每个神经元的感受野以及获取的信息都是全局的，基于全局的信息进行预测的。



8、为何YOLO连续的小目标以及紧连的多类目标效果不好

原因： 因为YOLO的预测是按照cell划分的，每个cell只预测了一个类别，每个cell也只预测了两个box，也就是说一个cell最多可以预测出两个同类的目标。这也是YOLO的从最开始思想上带来的缺陷。



9、YOLO定位不精准的原因

（1）最后使用全连接层预测了box的坐标，由于之前的全连接层的出现的，导致了物体位置信息的丢失，卷积层是有利于物体的位置信息的。

（2）每个cell就预测两个box，也导致了精度的低下。

（3）每个box从很小回归到很大过程，是基于局部的特征回归的，这样定位不准。在two-stage中，RPN会给出大致的box的位置，再回归预测，但是这里就不同了。

（4）大小box的定位误差是相同对待的，但是实际中，同样的误差，大box的比小box对IOU的影响要小很多。eg：同样的中心loss大小，对小box的IOU影响大，对大box的IOU影响小。



10、关于Box与GT之间匹配的一些理解（5.22与阳哥讨论后）

- 在YOLO中应该将所有GT的位置和长宽都是归一化的，同时GT与box之间的match都是在map上进行的，不是在原图上进行的，这点需要注意。

- YOLO中在训练中一个GT是只有GT与之对应。首先将GT的坐标归一化，对map的分为s*s的区域就可以得到GT匹配到哪个cell。这是第一步，cell与GT匹配。

- 每个cell有B个box，经过一轮后每个box都会有四个值（xy相对于cell左上角的偏移，以及wh都是归一化的）以及一个Confid值，根据xywh可以计算B个box中与GT的IOU最大的box，这样就可以得到box与GT对应起来，每个GT只会与一个cell中的一个box对应，对应box的confid的label值就是对应的IOU值。

- 关于loss中中心点位置的损失：![1526974178903](Temp\1526974178903.png)

  在train时，GT与cell对应后，GT的坐标就转化为相对于cell左上角的坐标（按照cell再归一化的），预测x^和y^也是相对于cell左上角的坐标（也是在cell内的，0到1的坐标值）。这样做的好处：在cell内归一化的坐标变化m，对应到全图偏移本质就只有m/7。这样可以让位置的预测和训练更稳定，如果都是基于全图的位置loss，这样位置预测就会出现不稳定。